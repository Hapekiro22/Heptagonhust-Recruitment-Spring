使用版本: v0.3.2
使用小测试集 (Small)
错误: VTune 未能成功加载，尝试其他加载方法...
VTune 版本信息：
Intel(R) VTune(TM) Profiler 2024.1.0 (build 627630) Command Line Tool
Copyright (C) 2009 Intel Corporation. All rights reserved.
===============================================
 VTune 分析报告 - 版本: v0.3.2 - 测试集: small
 开始时间: Mon Mar 24 10:55:33 PM CST 2025
===============================================



--- 开始 hotspots 分析 Mon Mar 24 10:55:33 PM CST 2025 ---
收集数据中，请等待...
Layer 0 :  Elapse time 3.530343 ms. (    0.00 GFlops) 
Layer 1 :  Elapse time 3.314336 ms. (    0.02 GFlops) 
Layer 2 :  Elapse time 3.645976 ms. (    0.68 GFlops) 
Layer 3 :  Elapse time 13.039668 ms. (   13.03 GFlops) 
Layer 4 :  Elapse time 105.365674 ms. (   51.59 GFlops) 
Total elapse time: 0.128896. (   43.51 GFlops) 
Elapsed Time: 0.882s
    CPU Time: 3.780s
        Effective Time: 3.780s
        Spin Time: 0s
        Overhead Time: 0s
    Total Thread Count: 64
    Paused Time: 0s

Top Hotspots
Function                          Module    CPU Time  % of CPU Time(%)
--------------------------------  --------  --------  ----------------
sgemm._omp_fn.0                   winograd    0.788s             20.8%
image_transform._omp_fn.0         winograd    0.778s             20.6%
output_transform._omp_fn.0        winograd    0.736s             19.5%
output_unpacking_store._omp_fn.0  winograd    0.574s             15.2%
image_packing._omp_fn.0           winograd    0.512s             13.5%
[Others]                          N/A         0.392s             10.4%
Effective CPU Utilization: 8.1%
 | The metric value is low, which may signal a poor logical CPU cores
 | utilization caused by load imbalance, threading runtime overhead, contended
 | synchronization, or thread/process underutilization. Explore sub-metrics to
 | estimate the efficiency of MPI and OpenMP parallelism or run the Locks and
 | Waits analysis to identify parallel bottlenecks for other parallel runtimes.
 |
    Average Effective CPU Utilization: 5.184 out of 64
Collection and Platform Info
    Application Command Line: numactl "--cpunodebind=0" "--membind=0" "./winograd" "conf/small.conf" 
    Operating System: 5.15.0-100-generic DISTRIB_ID=Ubuntu DISTRIB_RELEASE=22.04 DISTRIB_CODENAME=jammy DISTRIB_DESCRIPTION="Ubuntu 22.04.4 LTS"
    Computer Name: hepnode1
    Result Size: 4.0 MB 
    Collection start time: 14:55:36 24/03/2025 UTC
    Collection stop time: 14:55:37 24/03/2025 UTC
    Collector Type: Driverless Perf per-process counting,User-mode sampling and tracing
    CPU
        Name: Intel(R) Xeon(R) Processor code named Icelake
        Frequency: 1.995 GHz
        Logical CPU Count: 64
        LLC size: 50.3 MB 
        Cache Allocation Technology
            Level 2 capability: not detected
            Level 3 capability: available

If you want to skip descriptions of detected performance issues in the report,
enter: vtune -report summary -report-knob show-issues=false -r <my_result_dir>.
Alternatively, you may view the report in the csv format: vtune -report
<report_name> -format=csv.
数据收集成功！生成报告...
分析完成: hotspots
结果保存在: vtune_results/v0.3.2/hotspots_small_20250324_225533



--- 开始 memory-access 分析 Mon Mar 24 10:55:43 PM CST 2025 ---
收集数据中，请等待...
Layer 0 :  Elapse time 1.550674 ms. (    0.01 GFlops) 
Layer 1 :  Elapse time 1.533031 ms. (    0.05 GFlops) 
Layer 2 :  Elapse time 1.910289 ms. (    1.30 GFlops) 
Layer 3 :  Elapse time 7.678668 ms. (   22.12 GFlops) 
Layer 4 :  Elapse time 71.338018 ms. (   76.20 GFlops) 
Total elapse time: 0.084011. (   66.76 GFlops) 
Elapsed Time: 0.269s
 | Application execution time is too short. Metrics data may be unreliable.
 | Consider reducing the sampling interval or increasing your application
 | execution time.
 |
    CPU Time: 2.566s
    Memory Bound: 63.2% of Pipeline Slots
     | The metric value is high. This may indicate that a significant fraction
     | of execution pipeline slots could be stalled due to demand memory load
     | and stores. Explore the metric breakdown by memory hierarchy, memory
     | bandwidth information, and correlation by memory objects.
     |
        L1 Bound: 25.1% of Clockticks
         | This metric shows how often machine was stalled without missing the
         | L1 data cache. The L1 cache typically has the shortest latency.
         | However, in certain cases like loads blocked on older stores, a load
         | might suffer a high latency even though it is being satisfied by the
         | L1.
         |
        L2 Bound: 15.1% of Clockticks
         | This metric shows how often machine was stalled on L2 cache. Avoiding
         | cache misses (L1 misses/L2 hits) will improve the latency and
         | increase performance.
         |
        L3 Bound: 0.0% of Clockticks
        DRAM Bound: 0.3% of Clockticks
            DRAM Bandwidth Bound: 0.0% of Elapsed Time
        Store Bound: 0.0% of Clockticks
        NUMA: % of Remote Accesses: 0.0%
        UPI Utilization Bound: 0.0% of Elapsed Time
    Loads: 544,266,039
    Stores: 225,506,628
    LLC Miss Count: 0
        Local Memory Access Count: 0
        Remote Memory Access Count: 0
        Remote Cache Access Count: 0
    Total Thread Count: 65
    Paused Time: 0s

Bandwidth Utilization
Bandwidth Domain                  Platform Maximum  Observed Maximum  Average  % of Elapsed Time with High BW Utilization(%)
--------------------------------  ----------------  ----------------  -------  ---------------------------------------------
DRAM, GB/sec                      180                         26.500    9.061                                           0.0%
DRAM Single-Package, GB/sec       90                          26.400    9.284                                           0.0%
UPI Utilization Single-link, (%)  100                          1.100    0.149                                           0.0%
Collection and Platform Info
    Application Command Line: numactl "--cpunodebind=0" "--membind=0" "./winograd" "conf/small.conf" 
    Operating System: 5.15.0-100-generic DISTRIB_ID=Ubuntu DISTRIB_RELEASE=22.04 DISTRIB_CODENAME=jammy DISTRIB_DESCRIPTION="Ubuntu 22.04.4 LTS"
    Computer Name: hepnode1
    Result Size: 9.8 MB 
    Collection start time: 14:56:01 24/03/2025 UTC
    Collection stop time: 14:56:01 24/03/2025 UTC
    Collector Type: Driverless Perf system-wide sampling
    CPU
        Name: Intel(R) Xeon(R) Processor code named Icelake
        Frequency: 1.995 GHz
        Logical CPU Count: 64
        Max DRAM Single-Package Bandwidth: 90.000 GB/s
        LLC size: 50.3 MB 
        Cache Allocation Technology
            Level 2 capability: not detected
            Level 3 capability: available

Recommendations:
    Increase execution time: 
     | Application execution time is too short. Metrics data may be unreliable.
     | Consider reducing the sampling interval or increasing your application
     | execution time.

If you want to skip descriptions of detected performance issues in the report,
enter: vtune -report summary -report-knob show-issues=false -r <my_result_dir>.
Alternatively, you may view the report in the csv format: vtune -report
<report_name> -format=csv.
数据收集成功！生成报告...
分析完成: memory-access
结果保存在: vtune_results/v0.3.2/memory-access_small_20250324_225533



--- 开始 threading 分析 Mon Mar 24 10:56:07 PM CST 2025 ---
收集数据中，请等待...
Layer 0 :  Elapse time 3.332297 ms. (    0.00 GFlops) 
Layer 1 :  Elapse time 2.602657 ms. (    0.03 GFlops) 
Layer 2 :  Elapse time 3.223022 ms. (    0.77 GFlops) 
Layer 3 :  Elapse time 18.759648 ms. (    9.06 GFlops) 
Layer 4 :  Elapse time 93.862613 ms. (   57.91 GFlops) 
Total elapse time: 0.121780. (   46.05 GFlops) 
Elapsed Time: 0.868s
    Paused Time: 0s
Effective CPU Utilization: 6.6% (4.252 out of 64 logical CPUs)
 | The metric value is low, which may signal a poor logical CPU cores
 | utilization caused by load imbalance, threading runtime overhead, contended
 | synchronization, or thread/process underutilization. Explore sub-metrics to
 | estimate the efficiency of MPI and OpenMP parallelism or run the Locks and
 | Waits analysis to identify parallel bottlenecks for other parallel runtimes.
 |
    Total Thread Count: 65
        Thread Oversubscription: 0s (0.0% of CPU Time)
    Wait Time with poor CPU Utilization: 0.000s (100.0% of Wait Time)

        Top Waiting Objects
        Sync Object                                                                    Wait Time with poor CPU Utilization  (% from Object Wait Time)(%)  Wait Count
        -----------------------------------------------------------------------------  -----------------------------------  ----------------------------  ----------
        Stream conf/small.conf 0x4e2c38dc                                                                           0.000s                        100.0%           1
        Stream /proc/self/status 0x3791b3a6                                                                         0.000s                        100.0%           1
        Stream /sys/devices/system/cpu/cpu0/topology/core_siblings_list 0x69712aff                                  0.000s                        100.0%           1
        Stream /sys/devices/system/cpu/cpu15/topology/thread_siblings_list 0x8b73d7cf                               0.000s                        100.0%           1
        Stream /sys/devices/system/cpu/cpu4/topology/thread_siblings_list 0x8b73d7cf                                0.000s                        100.0%           1
        [Others]                                                                                                    0.000s                        100.0%          20
    Spin and Overhead Time: 0s (0.0% of CPU Time)

        Top Functions with Spin or Overhead Time
        Function  Module  Spin and Overhead Time  (% from CPU Time)(%)
        --------  ------  ----------------------  --------------------
Collection and Platform Info
    Application Command Line: numactl "--cpunodebind=0" "--membind=0" "./winograd" "conf/small.conf" 
    Operating System: 5.15.0-100-generic DISTRIB_ID=Ubuntu DISTRIB_RELEASE=22.04 DISTRIB_CODENAME=jammy DISTRIB_DESCRIPTION="Ubuntu 22.04.4 LTS"
    Computer Name: hepnode1
    Result Size: 4.0 MB 
    Collection start time: 14:56:09 24/03/2025 UTC
    Collection stop time: 14:56:10 24/03/2025 UTC
    Collector Type: User-mode sampling and tracing
    CPU
        Name: Intel(R) Xeon(R) Processor code named Icelake
        Frequency
        Logical CPU Count: 64
        LLC size: 50.3 MB 
        Cache Allocation Technology
            Level 2 capability: not detected
            Level 3 capability: available

If you want to skip descriptions of detected performance issues in the report,
enter: vtune -report summary -report-knob show-issues=false -r <my_result_dir>.
Alternatively, you may view the report in the csv format: vtune -report
<report_name> -format=csv.
数据收集成功！生成报告...
分析完成: threading
结果保存在: vtune_results/v0.3.2/threading_small_20250324_225533



--- 开始 uarch-exploration 分析 Mon Mar 24 10:56:15 PM CST 2025 ---
收集数据中，请等待...
Layer 0 :  Elapse time 1.512369 ms. (    0.01 GFlops) 
Layer 1 :  Elapse time 1.570702 ms. (    0.04 GFlops) 
Layer 2 :  Elapse time 1.803637 ms. (    1.38 GFlops) 
Layer 3 :  Elapse time 7.856369 ms. (   21.62 GFlops) 
Layer 4 :  Elapse time 71.829716 ms. (   75.68 GFlops) 
Total elapse time: 0.084573. (   66.31 GFlops) 
Elapsed Time: 0.269s
 | Application execution time is too short. Metrics data may be unreliable.
 | Consider reducing the sampling interval or increasing your application
 | execution time.
 |
    Clockticks: 6,790,000,000
    Instructions Retired: 7,200,000,000
    CPI Rate: 0.943
    MUX Reliability
    Retiring: 0.0% of Pipeline Slots
        Light Operations: 0.0% of Pipeline Slots
            FP Arithmetic: 0.0% of uOps
                FP x87: 0.0% of uOps
                FP Scalar: 0.0% of uOps
                FP Vector: 0.0% of uOps
                    128-bit FP Vector: 0.0% of uOps
                    256-bit FP Vector: 0.0% of uOps
                    512-bit FP Vector: 0.0% of uOps
            Memory Operations: 0.0% of Pipeline Slots
            Branch Instructions: 0.0% of Pipeline Slots
            Nop Instructions: 0.0% of Pipeline Slots
            Other: 0.0% of Pipeline Slots
        Heavy Operations: 0.0% of Pipeline Slots
            Few Uops Instructions: 0.0% of Pipeline Slots
            Microcode Sequencer: 0.0% of Pipeline Slots
                Assists: 0.0% of Pipeline Slots
                CISC: 0.0% of Pipeline Slots
    Front-End Bound: 0.0% of Pipeline Slots
        Front-End Latency: 0.0% of Pipeline Slots
            ICache Misses: 0.0% of Clockticks
            ITLB Overhead: 0.0% of Clockticks
            Branch Resteers: 0.0% of Clockticks
                Mispredicts Resteers: 0.0% of Clockticks
                Clears Resteers: 0.0% of Clockticks
                Unknown Branches: 0.0% of Clockticks
            DSB Switches: 0.0% of Clockticks
            Length Changing Prefixes: 0.0% of Clockticks
            MS Switches: 0.0% of Clockticks
        Front-End Bandwidth: 0.0% of Pipeline Slots
            Front-End Bandwidth MITE: 0.0% of Pipeline Slots
                Decoder-0 Alone: 0.0% of Pipeline Slots
                %MITE_4wide: 0.0% of Clockticks
            Front-End Bandwidth DSB: 0.0% of Pipeline Slots
            (Info) DSB Coverage: 0.0%
            (Info) DSB Misses: 0.0% of Pipeline Slots
    Bad Speculation: 100.0% of Pipeline Slots
     | A significant proportion of pipeline slots containing useful work are
     | being cancelled. This can be caused by mispredicting branches or by
     | machine clears. Note that this metric value may be highlighted due to
     | Branch Resteers issue.
     |
        Branch Mispredict: 0.0% of Pipeline Slots
        Machine Clears: 100.0% of Pipeline Slots
         | Issue: A significant portion of execution time is spent handling
         | machine clears.
         | 
         | Tips: See the "Memory Disambiguation" section in the Intel 64 and
         | IA-32 Architectures Optimization Reference Manual.
         |
    Back-End Bound: 0.0% of Pipeline Slots
        Memory Bound: 0.0% of Pipeline Slots
            L1 Bound: 0.0% of Clockticks
                DTLB Overhead: 0.0% of Clockticks
                    Load STLB Hit: 0.0% of Clockticks
                    Load STLB Miss: 0.0% of Clockticks
                Loads Blocked by Store Forwarding: 0.0% of Clockticks
                Lock Latency: 0.0% of Clockticks
                Split Loads: 0.0% of Clockticks
                4K Aliasing: 4.1% of Clockticks
                FB Full: 0.0% of Clockticks
            L2 Bound: 0.0% of Clockticks
            L3 Bound: 0.0% of Clockticks
                Contested Accesses: 0.0% of Clockticks
                Data Sharing: 0.0% of Clockticks
                L3 Latency: 0.0% of Clockticks
                SQ Full: 0.0% of Clockticks
            DRAM Bound: 0.0% of Clockticks
                Memory Bandwidth: 0.0% of Clockticks
                Memory Latency: 0.0% of Clockticks
                    Local Memory: 0.0% of Clockticks
                    Remote Memory: 0.0% of Clockticks
                    Remote Cache: 0.0% of Clockticks
            Store Bound: 0.0% of Clockticks
                Store Latency: 21.2% of Clockticks
                False Sharing: 0.0% of Clockticks
                Split Stores: 0.0%
                Streaming Stores: 0.0% of Clockticks
                DTLB Store Overhead
                    Store STLB Hit
                    Store STLB Miss
        Core Bound: 0.0% of Pipeline Slots
            Divider: 14.6% of Clockticks
            Port Utilization: 0.0% of Clockticks
                Cycles of 0 Ports Utilized: 0.0% of Clockticks
                    Serializing Operations: 17.8% of Clockticks
                        Slow Pause: 0.0% of Clockticks
                    Mixing Vectors: 0.0% of Clockticks
                Cycles of 1 Port Utilized: 0.0% of Clockticks
                Cycles of 2 Ports Utilized: 0.0% of Clockticks
                Cycles of 3+ Ports Utilized: 55.7% of Clockticks
                    ALU Operation Utilization
                        Port 0
                        Port 1
                        Port 5
                        Port 6
                    Load Operation Utilization
                    Store Operation Utilization
    Average CPU Frequency: 2.504 GHz
    Total Thread Count: 65
    Paused Time: 0s
Effective CPU Utilization: 15.7%
 | The metric value is low, which may signal a poor logical CPU cores
 | utilization caused by load imbalance, threading runtime overhead, contended
 | synchronization, or thread/process underutilization. Explore sub-metrics to
 | estimate the efficiency of MPI and OpenMP parallelism or run the Locks and
 | Waits analysis to identify parallel bottlenecks for other parallel runtimes.
 |
    Average Effective CPU Utilization: 10.070 out of 64
Collection and Platform Info
    Application Command Line: numactl "--cpunodebind=0" "--membind=0" "./winograd" "conf/small.conf" 
    Operating System: 5.15.0-100-generic DISTRIB_ID=Ubuntu DISTRIB_RELEASE=22.04 DISTRIB_CODENAME=jammy DISTRIB_DESCRIPTION="Ubuntu 22.04.4 LTS"
    Computer Name: hepnode1
    Result Size: 6.1 MB 
    Collection start time: 14:56:20 24/03/2025 UTC
    Collection stop time: 14:56:21 24/03/2025 UTC
    Collector Type: Driverless Perf system-wide sampling
    CPU
        Name: Intel(R) Xeon(R) Processor code named Icelake
        Frequency: 1.995 GHz
        Logical CPU Count: 64
        LLC size: 50.3 MB 
        Cache Allocation Technology
            Level 2 capability: not detected
            Level 3 capability: available

If you want to skip descriptions of detected performance issues in the report,
enter: vtune -report summary -report-knob show-issues=false -r <my_result_dir>.
Alternatively, you may view the report in the csv format: vtune -report
<report_name> -format=csv.
数据收集成功！生成报告...
分析完成: uarch-exploration
结果保存在: vtune_results/v0.3.2/uarch-exploration_small_20250324_225533



===============================================
 所有分析完成！
 结束时间: Mon Mar 24 10:56:27 PM CST 2025
 结果位置: vtune_results/v0.3.2
===============================================
创建了索引文件: vtune_results/v0.3.2/index.html
正在启动 VTune 后端服务，端口: 8080...
VTune 后端服务已启动，PID: 1201087
可通过浏览器访问: http://hepnode1:8080
后端服务将持续运行12小时，之后自动停止
VTune 分析完成。可使用以下命令停止后端服务:
kill $(cat vtune_results/v0.3.2/backend_pid.txt)
